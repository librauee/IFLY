{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('训练集/train.txt', header=None, names=['pid', 'label', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "test = pd.read_csv('测试集/apply_new.txt', header=None, names=['pid', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tagid'] = data['tagid'].apply(lambda x: eval(x))\n",
    "sentences = data['tagid'].values.tolist()\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [str(x) for x in sentences[i]]\n",
    "\n",
    "emb_size = 32\n",
    "model = Word2Vec(sentences, size=emb_size, window=6, min_count=5, sg=0, hs=0, seed=1, iter=5)\n",
    "\n",
    "emb_matrix = []\n",
    "for seq in sentences:\n",
    "    vec = []\n",
    "    for w in seq:\n",
    "        if w in model.wv.vocab:\n",
    "            vec.append(model.wv[w])\n",
    "    if len(vec) > 0:\n",
    "        emb_matrix.append(np.mean(vec, axis=0))\n",
    "    else:\n",
    "        emb_matrix.append([0] * emb_size)\n",
    "emb_matrix = np.array(emb_matrix)\n",
    "for i in range(emb_size):\n",
    "    data['tag_emb_{}'.format(i)] = emb_matrix[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "trn_idx: [     0      1      2 ... 299997 299998 299999]\n",
      "val_idx: [     3      9     14 ... 299992 299993 299994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/opt/conda/envs/python3/lib/python3.6/site-packages/lightgbm/basic.py:1706: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['age', 'city', 'gender', 'province']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python3/lib/python3.6/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/python3/lib/python3.6/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.291108\tvalid_1's binary_error: 0.310967\n",
      "[200]\ttraining's binary_error: 0.273725\tvalid_1's binary_error: 0.308\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttraining's binary_error: 0.274321\tvalid_1's binary_error: 0.30755\n",
      "fold n°1\n",
      "trn_idx: [     0      1      2 ... 299996 299998 299999]\n",
      "val_idx: [    10     13     25 ... 299986 299988 299997]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.291517\tvalid_1's binary_error: 0.3108\n",
      "[200]\ttraining's binary_error: 0.273296\tvalid_1's binary_error: 0.307983\n",
      "[300]\ttraining's binary_error: 0.262546\tvalid_1's binary_error: 0.3075\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's binary_error: 0.266108\tvalid_1's binary_error: 0.306917\n",
      "fold n°2\n",
      "trn_idx: [     0      3      5 ... 299997 299998 299999]\n",
      "val_idx: [     1      2      4 ... 299961 299977 299982]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.291287\tvalid_1's binary_error: 0.310817\n",
      "[200]\ttraining's binary_error: 0.274096\tvalid_1's binary_error: 0.30805\n",
      "[300]\ttraining's binary_error: 0.263512\tvalid_1's binary_error: 0.306017\n",
      "[400]\ttraining's binary_error: 0.256517\tvalid_1's binary_error: 0.3064\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's binary_error: 0.259833\tvalid_1's binary_error: 0.3058\n",
      "fold n°3\n",
      "trn_idx: [     0      1      2 ... 299993 299994 299997]\n",
      "val_idx: [     5      6     12 ... 299996 299998 299999]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.291292\tvalid_1's binary_error: 0.311883\n",
      "[200]\ttraining's binary_error: 0.273671\tvalid_1's binary_error: 0.308183\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's binary_error: 0.273079\tvalid_1's binary_error: 0.307783\n",
      "fold n°4\n",
      "trn_idx: [     1      2      3 ... 299997 299998 299999]\n",
      "val_idx: [     0      7      8 ... 299967 299972 299973]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.290796\tvalid_1's binary_error: 0.311333\n",
      "[200]\ttraining's binary_error: 0.273054\tvalid_1's binary_error: 0.308967\n",
      "[300]\ttraining's binary_error: 0.262375\tvalid_1's binary_error: 0.3083\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's binary_error: 0.258958\tvalid_1's binary_error: 0.3068\n",
      "AUC score: 0.7629740783555556\n",
      "F1 score: 0.6874891832184634\n",
      "Precision score: 0.7001264851639123\n",
      "Recall score: 0.6753\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['gender', 'age', 'province', 'city']\n",
    "features = [i for i in data.columns if i not in ['pid', 'label', 'tagid', 'time', 'model', 'make']]\n",
    "\n",
    "data[cat_cols] = data[cat_cols].astype('category')\n",
    "X_train = data[~data['label'].isna()]\n",
    "X_test = data[data['label'].isna()]\n",
    "\n",
    "y = X_train['label']\n",
    "KF = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "params = {\n",
    "          'objective':'binary',\n",
    "          'metric':'binary_error',\n",
    "          'learning_rate':0.05,\n",
    "          'subsample':0.8,\n",
    "          'subsample_freq':3,\n",
    "          'colsample_btree':0.8,\n",
    "          'num_iterations': 10000,\n",
    "          'verbose':-1\n",
    "}\n",
    "oof_lgb = np.zeros(len(X_train))\n",
    "predictions_lgb = np.zeros((len(X_test)))\n",
    "# 特征重要性\n",
    "feat_imp_df = pd.DataFrame({'feat': features, 'imp': 0})\n",
    "# 五折交叉验证\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(X_train.values, y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print('trn_idx:',trn_idx)\n",
    "    print('val_idx:',val_idx)\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx][features],label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx][features],label=y.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(\n",
    "        params,\n",
    "        trn_data,\n",
    "        num_round,\n",
    "        valid_sets = [trn_data, val_data],\n",
    "        verbose_eval=100,\n",
    "        early_stopping_rounds=50,\n",
    "        categorical_feature=cat_cols,\n",
    "    )\n",
    "    feat_imp_df['imp'] += clf.feature_importance() / 5\n",
    "    oof_lgb[val_idx] = clf.predict(X_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions_lgb[:] += clf.predict(X_test[features], num_iteration=clf.best_iteration)\n",
    "print(\"AUC score: {}\".format(roc_auc_score(y, oof_lgb)))\n",
    "print(\"F1 score: {}\".format(f1_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))\n",
    "print(\"Precision score: {}\".format(precision_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))\n",
    "print(\"Recall score: {}\".format(recall_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
